{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Реализация градиентного спуска\n",
    "\n",
    "Реализуйте линейную регрессию с функцией потерь MSE, обучаемую с помощью:\n",
    "\n",
    "**Задание 1** Градиентного спуска;\n",
    "\n",
    "**Задание 2** Стохастического градиентного спуска.\n",
    "\n",
    "Во всех пунктах необходимо соблюдать следующие условия:\n",
    "\n",
    "* Все вычисления должны быть векторизованы;\n",
    "* Циклы средствами python допускается использовать только для итераций градиентного спуска;\n",
    "* В качестве критерия останова необходимо использовать (одновременно):\n",
    "\n",
    "    * проверку на евклидовую норму разности весов на двух соседних итерациях (например, меньше некоторого малого числа порядка $10^{-6}$, задаваемого параметром `tolerance`);\n",
    "    * достижение максимального числа итераций (например, 10000, задаваемого параметром `max_iter`).\n",
    "* Чтобы проследить, что оптимизационный процесс действительно сходится, будем использовать атрибут класса `loss_history` — в нём после вызова метода `fit` должны содержаться значения функции потерь для всех итераций, начиная с первой (до совершения первого шага по антиградиенту);\n",
    "* Инициализировать веса можно случайным образом или нулевым вектором."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearReg(BaseEstimator):\n",
    "    def __init__(self, gd_type='full', tolerance=1e-4, max_iter=1000, w0=None, alpha=1e-3, eta=1e-2, reg=None):\n",
    "        \"\"\"\n",
    "        gd_type: 'full' or 'stochastic' or 'momentum'\n",
    "        tolerance: for stopping gradient descent\n",
    "        max_iter: maximum number of steps in gradient descent\n",
    "        w0: np.array of shape (d) - init weights\n",
    "        eta: learning rate\n",
    "        alpha: momentum coefficient\n",
    "        reg: ridge regularization parameter, if it exists\n",
    "        \"\"\"\n",
    "        self.gd_type = gd_type\n",
    "        self.tolerance = tolerance\n",
    "        self.max_iter = max_iter\n",
    "        self.w0 = w0\n",
    "        self.alpha = alpha\n",
    "        self.w = None\n",
    "        self.eta = eta\n",
    "        self.reg = reg\n",
    "        self.loss_history = None  # list of loss function values at each training iteration\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        X: np.array of shape (ell, d)\n",
    "        y: np.array of shape (ell)\n",
    "        ---\n",
    "        output: self\n",
    "        \"\"\"\n",
    "        self.loss_history = []  \n",
    "        tmp_arr = np.random.uniform(-1/(2*X.shape[0]), 1/(2*X.shape[0]), X.shape[1])  # Uniform init with values ~ 0\n",
    "        self.w = self.w0.copy() if self.w0 is not None else tmp_arr\n",
    "        \n",
    "        for it in range(self.max_iter):\n",
    "            self.loss_history.append(self.calc_loss(X,y))\n",
    "            new_w = None\n",
    "            \n",
    "            if self.gd_type == 'full':\n",
    "                new_w = self.w - self.eta * self.calc_gradient(X, y)\n",
    "                \n",
    "            if self.gd_type == 'stochastic':\n",
    "                rand_index = np.random.randint(0, y.shape[0])\n",
    "                new_w = self.w - self.eta * self.calc_gradient(X[rand_index], y[rand_index])\n",
    "            \n",
    "            if np.linalg.norm(new_w - self.w, 2) < self.tolerance:\n",
    "                break\n",
    "                \n",
    "            self.w = new_w\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        if self.w is None:\n",
    "            raise Exception('Not trained yet')\n",
    "        \n",
    "        if (self.reg is not None): \n",
    "            w_norm = sum(map(lambda i: i * i, w))\n",
    "            return X @ self.w.T + self.reg * w_norm\n",
    "            \n",
    "        return X @ self.w.T\n",
    "    \n",
    "    def calc_gradient(self, X, y):\n",
    "        \"\"\"\n",
    "        X: np.array of shape (ell, d) (ell can be equal to 1 if stochastic)\n",
    "        y: np.array of shape (ell)\n",
    "        ---\n",
    "        output: np.array of shape (d)\n",
    "        \"\"\"\n",
    "        if (self.reg is not None):   \n",
    "            return 1/X.shape[0] * X.T.dot(X @ self.w.T - y.T) + self.reg/X.shape[0] * self.w.T\n",
    "        \n",
    "        return 1/X.shape[0] * X.T.dot(X @ self.w.T - y.T)\n",
    "            \n",
    "    def calc_loss(self, X, y):\n",
    "        \"\"\"\n",
    "        X: np.array of shape (ell, d)\n",
    "        y: np.array of shape (ell)\n",
    "        ---\n",
    "        output: float \n",
    "        \"\"\" \n",
    "        tmp = X @ self.w.T - y.T\n",
    "        if (self.reg is not None): \n",
    "            w_norm = sum(map(lambda i: i * i, w)) \n",
    "            return 1/(2 * X.shape[0]) * tmp * tmp.T + self.reg/(2 * X.shape[0]) * w_norm\n",
    "        \n",
    "        return 1/(2 * X.shape[0]) * tmp * tmp.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 3**. \n",
    "* Загрузите данные из домашнего задания 2 ([train.csv](https://www.kaggle.com/c/nyc-taxi-trip-duration/data));\n",
    "* Разбейте выборку на обучающую и тестовую в отношении 7:3 с random_seed=0;\n",
    "* Преобразуйте целевую переменную `trip_duration` как $\\hat{y} = \\log{(y + 1)}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>vendor_id</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>trip_duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id2875421</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-03-14 17:24:55</td>\n",
       "      <td>2016-03-14 17:32:30</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.982155</td>\n",
       "      <td>40.767937</td>\n",
       "      <td>-73.964630</td>\n",
       "      <td>40.765602</td>\n",
       "      <td>N</td>\n",
       "      <td>455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id2377394</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-06-12 00:43:35</td>\n",
       "      <td>2016-06-12 00:54:38</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.980415</td>\n",
       "      <td>40.738564</td>\n",
       "      <td>-73.999481</td>\n",
       "      <td>40.731152</td>\n",
       "      <td>N</td>\n",
       "      <td>663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id3858529</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-01-19 11:35:24</td>\n",
       "      <td>2016-01-19 12:10:48</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.979027</td>\n",
       "      <td>40.763939</td>\n",
       "      <td>-74.005333</td>\n",
       "      <td>40.710087</td>\n",
       "      <td>N</td>\n",
       "      <td>2124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id3504673</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-04-06 19:32:31</td>\n",
       "      <td>2016-04-06 19:39:40</td>\n",
       "      <td>1</td>\n",
       "      <td>-74.010040</td>\n",
       "      <td>40.719971</td>\n",
       "      <td>-74.012268</td>\n",
       "      <td>40.706718</td>\n",
       "      <td>N</td>\n",
       "      <td>429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id2181028</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-03-26 13:30:55</td>\n",
       "      <td>2016-03-26 13:38:10</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.973053</td>\n",
       "      <td>40.793209</td>\n",
       "      <td>-73.972923</td>\n",
       "      <td>40.782520</td>\n",
       "      <td>N</td>\n",
       "      <td>435</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  vendor_id      pickup_datetime     dropoff_datetime  \\\n",
       "0  id2875421          2  2016-03-14 17:24:55  2016-03-14 17:32:30   \n",
       "1  id2377394          1  2016-06-12 00:43:35  2016-06-12 00:54:38   \n",
       "2  id3858529          2  2016-01-19 11:35:24  2016-01-19 12:10:48   \n",
       "3  id3504673          2  2016-04-06 19:32:31  2016-04-06 19:39:40   \n",
       "4  id2181028          2  2016-03-26 13:30:55  2016-03-26 13:38:10   \n",
       "\n",
       "   passenger_count  pickup_longitude  pickup_latitude  dropoff_longitude  \\\n",
       "0                1        -73.982155        40.767937         -73.964630   \n",
       "1                1        -73.980415        40.738564         -73.999481   \n",
       "2                1        -73.979027        40.763939         -74.005333   \n",
       "3                1        -74.010040        40.719971         -74.012268   \n",
       "4                1        -73.973053        40.793209         -73.972923   \n",
       "\n",
       "   dropoff_latitude store_and_fwd_flag  trip_duration  \n",
       "0         40.765602                  N            455  \n",
       "1         40.731152                  N            663  \n",
       "2         40.710087                  N           2124  \n",
       "3         40.706718                  N            429  \n",
       "4         40.782520                  N            435  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('NY taxi_train.csv')\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('trip_duration', axis=1)\n",
    "y = np.log1p(data['trip_duration'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 4**. Обучите и провалидируйте модели на данных из предыдущего пункта, сравните качество между методами по метрикам MSE и $R^2$. Исследуйте влияние параметров `max_iter` и `eta` на процесс оптимизации. Согласуется ли оно с вашими ожиданиями?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выделим хотя бы какие-то признаки по времени из предыдущего задания, а также добавим сразу константый, так как наша регрессия по умолчанию его не добавляет:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_datetime = lambda row: datetime.datetime.strptime(row['pickup_datetime'], \"%Y-%m-%d %H:%M:%S\")\n",
    "X_train['pickup_datetime'] = data.apply(extract_datetime, axis=1)\n",
    "X_test['pickup_datetime'] = data.apply(extract_datetime, axis=1)\n",
    "\n",
    "X_train['year_day'] = X_train.apply(lambda row: row['pickup_datetime'].timetuple().tm_yday, axis=1)\n",
    "X_test['year_day'] = X_test.apply(lambda row: row['pickup_datetime'].timetuple().tm_yday, axis=1)\n",
    "\n",
    "X_train['weekday'] = X_train.apply(lambda row: row['pickup_datetime'].weekday(), axis=1)\n",
    "X_test['weekday'] = X_test.apply(lambda row: row['pickup_datetime'].weekday(), axis=1)\n",
    "\n",
    "X_train['hour'] =  X_train.apply(lambda row: row['pickup_datetime'].hour, axis=1)\n",
    "X_test['hour'] =  X_test.apply(lambda row: row['pickup_datetime'].hour, axis=1)\n",
    "\n",
    "X_train['month'] =  X_train.apply(lambda row: row['pickup_datetime'].month, axis=1)\n",
    "X_test['month'] =  X_test.apply(lambda row: row['pickup_datetime'].month, axis=1)\n",
    "\n",
    "X_train['blizzard'] = ((22 <= X_train.loc[:,'year_day']) & (X_train.loc[:,'year_day'] <= 24)).astype('int64')\n",
    "X_test['blizzard'] =  ((22 <= X_test.loc[:,'year_day']) & (X_test.loc[:,'year_day'] <= 24)).astype('int64')\n",
    "\n",
    "X_train['summer_anomaly'] =  ((149 <= X_train.loc[:,'year_day']) & (X_train.loc[:,'year_day'] <= 150)).astype('int64')\n",
    "X_test['summer_anomaly'] =  ((149 <= X_test.loc[:,'year_day']) & (X_test.loc[:,'year_day'] <= 150)).astype('int64')\n",
    "\n",
    "X_train['const'] = 1\n",
    "X_test['const'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.drop(\n",
    "    ['id', \n",
    "     'vendor_id', \n",
    "     'pickup_datetime', 'dropoff_datetime', \n",
    "     'passenger_count', \n",
    "     'pickup_longitude', 'pickup_latitude',\n",
    "     'dropoff_longitude', 'dropoff_latitude',\n",
    "     'store_and_fwd_flag'\n",
    "    ], axis=1, inplace=True)\n",
    "X_test.drop(\n",
    "    ['id', \n",
    "     'vendor_id', \n",
    "     'pickup_datetime', 'dropoff_datetime', \n",
    "     'passenger_count', \n",
    "     'pickup_longitude', 'pickup_latitude',\n",
    "     'dropoff_longitude', 'dropoff_latitude',\n",
    "     'store_and_fwd_flag'\n",
    "    ], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year_day</th>\n",
       "      <th>weekday</th>\n",
       "      <th>hour</th>\n",
       "      <th>month</th>\n",
       "      <th>blizzard</th>\n",
       "      <th>summer_anomaly</th>\n",
       "      <th>const</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>430252</th>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        year_day  weekday  hour  month  blizzard  summer_anomaly  const\n",
       "430252        46        0     0      2         0               0      1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1021050 entries, 430252 to 305711\n",
      "Data columns (total 7 columns):\n",
      "year_day          1021050 non-null int64\n",
      "weekday           1021050 non-null int64\n",
      "hour              1021050 non-null int64\n",
      "month             1021050 non-null int64\n",
      "blizzard          1021050 non-null int64\n",
      "summer_anomaly    1021050 non-null int64\n",
      "const             1021050 non-null int64\n",
      "dtypes: int64(7)\n",
      "memory usage: 62.3 MB\n"
     ]
    }
   ],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import make_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(bar_y, y):\n",
    "    return 1 / y.shape[0] * (bar_y - y) @ (bar_y - y).T\n",
    "\n",
    "def r2(bar_y, y):\n",
    "    return 1 - mse(bar_y, y) / mse(y.mean(), y)\n",
    "\n",
    "mse_scorer = make_scorer(\n",
    "    mse,\n",
    "    greater_is_better=False\n",
    ")\n",
    "\n",
    "r2_scorer = make_scorer(\n",
    "    r2,\n",
    "    greater_is_better=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = ['weekday', 'hour', 'month', 'blizzard', 'summer_anomaly']\n",
    "numeric_features = ['year_day']\n",
    "\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_transformer = ColumnTransformer([\n",
    "                                        ('ohe', OneHotEncoder(handle_unknown=\"ignore\"), categorical_features),\n",
    "                                        ('scaling', StandardScaler(), numeric_features)\n",
    "                                       ])\n",
    "\n",
    "gd_pipeline = Pipeline(steps=[\n",
    "                            ('ohe_and_scaling', column_transformer),\n",
    "                            ('regression', LinearReg(gd_type='full', max_iter=6666))\n",
    "                          ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE = 0.6507\n",
      "Test R2 = -0.0334\n",
      "-----\n",
      "CPU times: user 3min 28s, sys: 40.5 s, total: 4min 8s\n",
      "Wall time: 4min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = gd_pipeline.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print('Test MSE = %.4f' % mse(y_pred, y_test))\n",
    "y_pred = model.predict(X_test)\n",
    "print('Test R2 = %.4f' % r2(y_pred, y_test))\n",
    "print('-----')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Будем увеличить eta с тем же фиксированным числом иттераций и смотреть только на ошибки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for eta in [1e-1, 1e-3, 2e-2, 3e-2, 5e-2]:\n",
    "    gd_pipeline = Pipeline(steps=[\n",
    "                            ('ohe_and_scaling', column_transformer),\n",
    "                            ('regression', LinearReg(gd_type='full', max_iter=6666, eta=eta))\n",
    "                          ])\n",
    "    \n",
    "    model = gd_pipeline.fit(X_train, y_train)\n",
    "\n",
    "    print(f'eta = {eta}')\n",
    "    y_pred = model.predict(X_test)\n",
    "    print('Test MSE = %.4f' % mse(y_pred, y_test))\n",
    "    y_pred = model.predict(X_test)\n",
    "    print('Test R2 = %.4f' % r2(y_pred, y_test))\n",
    "    print('-----')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The kernel appears to have died. It will restart automatically.\n",
    "<br>*Либо мой PC не тянет, либо я не понял, что не так (stackover не помог).*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Будем изменять max_iter при наилучшей eta и смотреть только на ошибки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for n_iter in [7500, 5000, 2500, 1000, 100]:\n",
    "    gd_pipeline = Pipeline(steps=[\n",
    "                            ('ohe_and_scaling', column_transformer),\n",
    "                            ('regression', LinearReg(gd_type='full', max_iter=n_iter, eta=))\n",
    "                          ])\n",
    "    \n",
    "    model = gd_pipeline.fit(X_train, y_train)\n",
    "\n",
    "    print(f'max_iter = {n_iter}')\n",
    "    y_pred = model.predict(X_test)\n",
    "    print('Test MSE = %.4f' % mse(y_pred, y_test))\n",
    "    y_pred = model.predict(X_test)\n",
    "    print('Test R2 = %.4f' % r2(y_pred, y_test))\n",
    "    print('-----')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заметим, что ... . Продолжим подбирать  eta:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for eta in [0.15, 0.2, 0.25, 0.5, 1, 2, 5]:\n",
    "    rgd_pipeline = Pipeline(steps=[\n",
    "                            ('ohe_and_scaling', column_transformer),\n",
    "                            ('regression', LinearReg(gd_type='full', max_iter=, eta=eta))\n",
    "                          ])\n",
    "    \n",
    "    model = gd_pipeline.fit(X_train, y_train)\n",
    "\n",
    "    print(f'eta = {eta}')\n",
    "    y_pred = model.predict(X_test)\n",
    "    print('Test MSE = %.4f' % mse(y_pred, y_test))\n",
    "    y_pred = model.predict(X_test)\n",
    "    print('Test R2 = %.4f' % r2(y_pred, y_test))\n",
    "    print('-----')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Полученные оптимальные параметры: `eta = , max_iter = `."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь займемся стохастическим градиентным спуском. Для этого сначала убедимся, что он работает:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_pipeline = Pipeline(steps=[\n",
    "                            ('ohe_and_scaling', column_transformer),\n",
    "                            ('regression', LinearReg(gd_type='stochastic', max_iter=2500 , eta=0.1))\n",
    "                          ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE = 0.9270\n",
      "Test R2 = -0.4723\n",
      "-----\n",
      "CPU times: user 7.76 s, sys: 2.91 s, total: 10.7 s\n",
      "Wall time: 11.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = sgd_pipeline.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print('Test MSE = %.4f' % mse(y_pred, y_test))\n",
    "y_pred = model.predict(X_test)\n",
    "print('Test R2 = %.4f' % r2(y_pred, y_test))\n",
    "print('-----')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Стоит отметить, что считается все гораздо быстрее. Попробуем поперебирать `eta` на уменьшенном числе итераций:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for eta in [1e-1, 1e-3, 2e-2, 3e-2, 5e-2]:\n",
    "    sgd_pipeline = Pipeline(steps=[\n",
    "                            ('ohe_and_scaling', column_transformer),\n",
    "                            ('regression', LinearReg(gd_type='stochastic', max_iter=1000 , eta=eta, tolerance=1e-4))\n",
    "                          ])\n",
    "    \n",
    "    model = sgd_pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    print(f'eta = {eta}')\n",
    "    y_pred = model.predict(X_test)\n",
    "    print('Test MSE = %.4f' % mse(y_pred, y_test))\n",
    "    y_pred = model.predict(X_test)\n",
    "    print('Test R2 = %.4f' % r2(y_pred, y_test))\n",
    "    print('-----')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The kernel appears to have died. It will restart automatically.\n",
    "<br>*Либо мой PC не тянет, либо я не понял, что не так (stackover не помог).*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Локальный минимум после двух перезапусков находится около . Будем считать это оптимумом. \n",
    "<br>Увеличим число итераций:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for n_iter in [1500, 2000, 2500, 3000, 3500]:\n",
    "    sgd_pipeline = Pipeline(steps=[\n",
    "                            ('ohe_and_scaling', column_transformer),\n",
    "                            ('regression', LinearReg(gd_type='stochastic', max_iter=n_iter , eta=))\n",
    "                          ])\n",
    "    \n",
    "    model = sgd_pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    print(f'max_iter = {n_iter}')\n",
    "    y_pred = model.predict(X_test)\n",
    "    print('Test MSE = %.4f' % mse(y_pred, y_test))\n",
    "    y_pred = model.predict(X_test)\n",
    "    print('Test R2 = %.4f' % r2(y_pred, y_test))\n",
    "    print('-----')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что ... . Теперь будем явно выводить число проведенных итераций:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for eta in [1e-2, 1e-3, 2e-2, 3e-1, 5e-3]:\n",
    "    sgd_pipeline = Pipeline(steps=[\n",
    "                            ('ohe_and_scaling', column_transformer),\n",
    "                            ('regression', LinearReg(gd_type='stochastic', max_iter= , eta=eta))\n",
    "                          ])\n",
    "    \n",
    "    print(f'eta = {eta}')\n",
    "    y_pred = model.predict(X_test)\n",
    "    print('Test MSE = %.4f' % mse(y_pred, y_test))\n",
    "    y_pred = model.predict(X_test)\n",
    "    print('Test R2 = %.4f' % r2(y_pred, y_test))\n",
    "    print('Number of iterations:', len(regressor.loss_history))\n",
    "    print('-----')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вывод: ... . Попробуем уменьшить tolerance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for eta in [1e-2, 1e-3, 2e-2, 3e-1, 5e-3]:\n",
    "    sgd_pipeline = Pipeline(steps=[\n",
    "                            ('ohe_and_scaling', column_transformer),\n",
    "                            ('regression', LinearReg(gd_type='stochastic', max_iter= , eta=eta, tolerance=1e-6))\n",
    "                          ])\n",
    "    \n",
    "    print(f'eta = {eta}')\n",
    "    y_pred = model.predict(X_test)\n",
    "    print('Test MSE = %.4f' % mse(y_pred, y_test))\n",
    "    y_pred = model.predict(X_test)\n",
    "    print('Test R2 = %.4f' % r2(y_pred, y_test))\n",
    "    print('Number of iterations:', len(regressor.loss_history))\n",
    "    print('-----')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем увеличить число итераций:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for iters in [2500, 3000, 3500, 5000, 7500]:\n",
    "    sgd_pipeline = Pipeline(steps=[\n",
    "                            ('ohe_and_scaling', column_transformer),\n",
    "                            ('regression', LinearReg(gd_type='stochastic', max_iter=n_iter , eta=, tolerance=1e-6)))\n",
    "                          ])\n",
    "    \n",
    "    print(f'max_iter = {n_iter}')\n",
    "    y_pred = model.predict(X_test)\n",
    "    print('Test MSE = %.4f' % mse(y_pred, y_test))\n",
    "    y_pred = model.predict(X_test)\n",
    "    print('Test R2 = %.4f' % r2(y_pred, y_test))\n",
    "    print('Number of iterations:', len(regressor.loss_history))\n",
    "    print('-----')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пусть оптимальными параметрами будут: `eta = , max_iter = `, `tolerance =`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Общий вывод: ... ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 5**. Постройте графики (на одной и той же картинке) зависимости величины функции потерь от номера итерации для полного, стохастического градиентного спусков. Сделайте выводы о скорости сходимости различных модификаций градиентного спуска."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = LinearReg(gd_type='full', max_iter=2500, eta=0.1) # Возьмем оптимальные параметры\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "full_loss_history = regressor.loss_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The kernel appears to have died. It will restart automatically.\n",
    "<br>*Либо мой PC не тянет, либо я не понял, что не так (stackover не помог).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = LinearReg(gd_type='stochastic', max_iter=3500, eta=0.02, tolerance=1e-6) # Возьмем оптимальные параметры\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "stoch_loss_history = regressor.loss_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(full_loss_history), len(stoch_loss_history))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(full_loss_history).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(stoch_loss_history).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CompareLoss(loss1, loss2):\n",
    "    fig, ax = plt.subplots(ncols=1, nrows=1, figsize=(20,10))\n",
    "    \n",
    "    ax.set_title('Comparing full GD and stochastic GD')\n",
    "    ax.set_xlabel('Iterations')\n",
    "    ax.set_ylabel('MSE')\n",
    "    \n",
    "    ax.set_ylim((0, 20))\n",
    "    \n",
    "    ax.plot(loss1, color='blue', label='full GD')\n",
    "    ax.plot(loss2, color='red', label='stochastic GD')\n",
    "    ax.legend()\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CompareLoss(full_loss_history, stoch_loss_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Общий вывод: ... ."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
